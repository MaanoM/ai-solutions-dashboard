{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b22f7e0",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa7f362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d45c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "n_records = 500000\n",
    "\n",
    "ip_ranges = [\n",
    "    '128.1.0.', '155.55.0.', '157.20.5.', '157.20.20.', '157.20.30.',\n",
    "    '192.168.1.', '10.0.0.', '172.16.0.'\n",
    "]\n",
    "urls = [\n",
    "    '/ai-assistant', '/demo-request', '/pricing', '/events',\n",
    "    '/job-prototype', '/solutions', '/contact', '/about',\n",
    "    '/ai-assistant/chat', '/demo-request/schedule',\n",
    "    '/events/upcoming', '/job-prototype/submit'\n",
    "]\n",
    "\n",
    "interaction_map = {\n",
    "    '/ai-assistant': 'AI Assistant Request',\n",
    "    '/ai-assistant/chat': 'AI Chat Initiated',\n",
    "    '/demo-request': 'Demo Inquiry',\n",
    "    '/demo-request/schedule': 'Demo Scheduled',\n",
    "    '/job-prototype': 'Job Prototype Inquiry',\n",
    "    '/job-prototype/submit': 'Job Prototype Submitted',\n",
    "    '/events': 'Event Inquiry',\n",
    "    '/events/upcoming': 'Event Registered',\n",
    "    '/pricing': 'Pricing Viewed',\n",
    "    '/solutions': 'Solutions Browsed',\n",
    "    '/contact': 'Contact Request',\n",
    "    '/about': 'About Page Viewed'\n",
    "}\n",
    "\n",
    "methods = ['GET', 'POST', 'PUT']\n",
    "status_codes = [200, 201, 301, 302, 304, 400, 403, 404, 500]\n",
    "salespeople = ['Maano', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank']\n",
    "products = ['AI Suite', 'DataPro', 'InsightX', 'VisionBot', 'CloudSync']\n",
    "countries = ['USA', 'UK', 'Germany', 'India', 'Canada', 'Australia']\n",
    "job_types = ['Consultation', 'Integration', 'Support', 'Training', 'Demo']\n",
    "\n",
    "# Generate dates spanning 36 months (3 years) for three full seasonal cycles\n",
    "start_date = datetime.now() - timedelta(days=1095)  # 1095 days = 3 years\n",
    "timestamps = [\n",
    "    (start_date + timedelta(\n",
    "        days=random.randint(0, 1095),\n",
    "        hours=random.randint(0, 23),\n",
    "        minutes=random.randint(0, 59),\n",
    "        seconds=random.randint(0, 59)))\n",
    "    for _ in range(n_records)\n",
    "]\n",
    "\n",
    "# More realistic URL distribution\n",
    "url_weights = [0.25, 0.15, 0.12, 0.1, 0.08, 0.08, 0.06, 0.05, 0.03, 0.03, 0.03, 0.02]\n",
    "random_urls = random.choices(urls, weights=url_weights, k=n_records)\n",
    "\n",
    "data = {\n",
    "    'timestamp': [ts.strftime('%d/%m/%Y %H:%M:%S') for ts in timestamps],\n",
    "    'ip_address': [f\"{random.choice(ip_ranges)}{random.randint(1, 255)}\" for _ in range(n_records)],\n",
    "    'method': [random.choices(methods, weights=[0.85, 0.12, 0.03])[0] for _ in range(n_records)],\n",
    "    'url': random_urls,\n",
    "    'status_code': [random.choices(status_codes, weights=[0.82, 0.05, 0.03, 0.02, 0.02, 0.02, 0.015, 0.015, 0.01])[0] for _ in range(n_records)],\n",
    "    'salesperson': [random.choices(salespeople, weights=[0.3, 0.2, 0.2, 0.15, 0.1, 0.05])[0] for _ in range(n_records)],\n",
    "    'product_sold': [random.choices(products, weights=[0.35, 0.25, 0.2, 0.15, 0.05])[0] for _ in range(n_records)],\n",
    "    'date_of_sale': [ts.strftime('%d/%m/%Y %H:%M:%S') for ts in timestamps],\n",
    "    'cost': [round(random.choices([\n",
    "        random.uniform(500, 1000),\n",
    "        random.uniform(1000, 2000),\n",
    "        random.uniform(2000, 3500),\n",
    "        random.uniform(3500, 5000)\n",
    "    ], weights=[0.4, 0.3, 0.2, 0.1])[0], 2) for _ in range(n_records)],\n",
    "    'customer_country': [random.choices(countries, weights=[0.35, 0.25, 0.15, 0.12, 0.08, 0.05])[0] for _ in range(n_records)],\n",
    "    'job_type_requested': [random.choices(job_types, weights=[0.3, 0.25, 0.2, 0.15, 0.1])[0] for _ in range(n_records)],\n",
    "    'customer_interaction': [interaction_map[url] for url in random_urls],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fe1af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "top1000 = df.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3197fc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_exists': True, 'structure_valid': True, 'not_empty': True, 'missing_columns': []}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def validate_iis_log_csv(file_path, required_columns=None, nrows=100):\n",
    "    \"\"\"\n",
    "    Validates if the CSV at file_path matches expected IIS log structure and is not empty.\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "        required_columns (list): List of required column names.\n",
    "        nrows (int): Number of rows to check for completeness.\n",
    "    Returns:\n",
    "        dict: Validation results.\n",
    "    \"\"\"\n",
    "    result = {'file_exists': False, 'structure_valid': False, 'not_empty': False, 'missing_columns': []}\n",
    "    if not os.path.isfile(file_path):\n",
    "        return result\n",
    "\n",
    "    result['file_exists'] = True\n",
    "    try:\n",
    "        sample = pd.read_csv(file_path, nrows=nrows)\n",
    "        result['not_empty'] = not sample.empty\n",
    "        if required_columns:\n",
    "            missing = [col for col in required_columns if col not in sample.columns]\n",
    "            result['missing_columns'] = missing\n",
    "            result['structure_valid'] = len(missing) == 0\n",
    "        else:\n",
    "            result['structure_valid'] = True\n",
    "    except Exception as e:\n",
    "        result['error'] = str(e)\n",
    "    return result\n",
    "\n",
    "iis_required_columns = [\n",
    "    'timestamp', 'ip_address', 'method', 'url', 'status_code',\n",
    "    'salesperson', 'product_sold', 'date_of_sale', 'cost',\n",
    "    'customer_country', 'job_type_requested', 'customer_interaction'\n",
    "]\n",
    "validation = validate_iis_log_csv('ai_solutions_web_sales_logs.csv', required_columns=iis_required_columns)\n",
    "print(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e44f24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "df.to_csv('ai_solutions_web_sales_logs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e53a26a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 12)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ai_solutions_web_sales_logs.csv', parse_dates=['date_of_sale'], dayfirst=True)\n",
    "print(df.shape)\n",
    "df['month'] = df['date_of_sale'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cb8ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales = df.groupby('month')['cost'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3f2aff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(monthly_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c8419d",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0e2f1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Date Dimension\\ndate_dim = df['date_of_sale'].unique()\\ndate_dim = pd.DataFrame(date_dim, columns=['date'])\\ndate_dim['date_id'] = date_dim.index\\ndate_dim['date'] = pd.to_datetime(date_dim['date'])\\ndate_dim['year'] = date_dim['date'].dt.year\\ndate_dim['month'] = date_dim['date'].dt.month\\ndate_dim['day'] = date_dim['date'].dt.day\\ndate_dim['day_of_week'] = date_dim['date'].dt.dayofweek\\ndate_dim['day_name'] = date_dim['date'].dt.day_name()\\ndate_dim['month_name'] = date_dim['date'].dt.month_name()\\n\\n# Customer Location Dimension\\nlocation_dim = pd.DataFrame(countries, columns=['country'])\\nlocation_dim['location_id'] = location_dim.index\\n\\n# Salesperson Dimension \\nsalesperson_dim = pd.DataFrame(salespeople, columns=['salesperson_name'])\\nsalesperson_dim['salesperson_id'] = salesperson_dim.index\\n\\n# Product Dimension\\nproduct_dim = pd.DataFrame(products, columns=['product_name'])\\nproduct_dim['product_id'] = product_dim.index\\n\\n# Job Type Dimension\\njob_type_dim = pd.DataFrame(job_types, columns=['job_type'])\\njob_type_dim['job_type_id'] = job_type_dim.index\\n\\n# Create fact table\\nfact_table = df.copy()\\n\\n# Join with dimension tables to get IDs\\nfact_table['date_id'] = pd.to_datetime(fact_table['date_of_sale']).map(dict(zip(date_dim['date'], date_dim['date_id'])))\\nfact_table['location_id'] = fact_table['customer_country'].map(dict(zip(location_dim['country'], location_dim['location_id'])))\\nfact_table['salesperson_id'] = fact_table['salesperson'].map(dict(zip(salesperson_dim['salesperson_name'], salesperson_dim['salesperson_id'])))\\nfact_table['product_id'] = fact_table['product_sold'].map(dict(zip(product_dim['product_name'], product_dim['product_id'])))\\nfact_table['job_type_id'] = fact_table['job_type_requested'].map(dict(zip(job_type_dim['job_type'], job_type_dim['job_type_id'])))\\n\\n# Select only needed columns for fact table\\nfact_table = fact_table[['date_id', 'location_id', 'salesperson_id', 'product_id', 'job_type_id', \\n                        'cost', 'status_code', 'customer_interaction']]\\n\\n\\n                        \""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dimension tables and fact table\n",
    "\"\"\"\n",
    "# Date Dimension\n",
    "date_dim = df['date_of_sale'].unique()\n",
    "date_dim = pd.DataFrame(date_dim, columns=['date'])\n",
    "date_dim['date_id'] = date_dim.index\n",
    "date_dim['date'] = pd.to_datetime(date_dim['date'])\n",
    "date_dim['year'] = date_dim['date'].dt.year\n",
    "date_dim['month'] = date_dim['date'].dt.month\n",
    "date_dim['day'] = date_dim['date'].dt.day\n",
    "date_dim['day_of_week'] = date_dim['date'].dt.dayofweek\n",
    "date_dim['day_name'] = date_dim['date'].dt.day_name()\n",
    "date_dim['month_name'] = date_dim['date'].dt.month_name()\n",
    "\n",
    "# Customer Location Dimension\n",
    "location_dim = pd.DataFrame(countries, columns=['country'])\n",
    "location_dim['location_id'] = location_dim.index\n",
    "\n",
    "# Salesperson Dimension \n",
    "salesperson_dim = pd.DataFrame(salespeople, columns=['salesperson_name'])\n",
    "salesperson_dim['salesperson_id'] = salesperson_dim.index\n",
    "\n",
    "# Product Dimension\n",
    "product_dim = pd.DataFrame(products, columns=['product_name'])\n",
    "product_dim['product_id'] = product_dim.index\n",
    "\n",
    "# Job Type Dimension\n",
    "job_type_dim = pd.DataFrame(job_types, columns=['job_type'])\n",
    "job_type_dim['job_type_id'] = job_type_dim.index\n",
    "\n",
    "# Create fact table\n",
    "fact_table = df.copy()\n",
    "\n",
    "# Join with dimension tables to get IDs\n",
    "fact_table['date_id'] = pd.to_datetime(fact_table['date_of_sale']).map(dict(zip(date_dim['date'], date_dim['date_id'])))\n",
    "fact_table['location_id'] = fact_table['customer_country'].map(dict(zip(location_dim['country'], location_dim['location_id'])))\n",
    "fact_table['salesperson_id'] = fact_table['salesperson'].map(dict(zip(salesperson_dim['salesperson_name'], salesperson_dim['salesperson_id'])))\n",
    "fact_table['product_id'] = fact_table['product_sold'].map(dict(zip(product_dim['product_name'], product_dim['product_id'])))\n",
    "fact_table['job_type_id'] = fact_table['job_type_requested'].map(dict(zip(job_type_dim['job_type'], job_type_dim['job_type_id'])))\n",
    "\n",
    "# Select only needed columns for fact table\n",
    "fact_table = fact_table[['date_id', 'location_id', 'salesperson_id', 'product_id', 'job_type_id', \n",
    "                        'cost', 'status_code', 'customer_interaction']]\n",
    "                        \n",
    "                        \n",
    "                        \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CET333",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
